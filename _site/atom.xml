<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Sanchit Alekh</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2017-05-05T01:59:17+02:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Sanchit Alekh</name>
   <email></email>
 </author>

 
 <entry>
   <title>Feature Extraction And Statistical Analysis Of Ragas In Indian Classical Music - A Summary</title>
   <link href="http://localhost:4000/2017/05/01/computer-music/"/>
   <updated>2017-05-01T00:00:00+02:00</updated>
   <id>http://localhost:4000/2017/05/01/computer-music</id>
   <content type="html">&lt;p&gt;Hindustani Classical Music is a music form originating from the northern part of India. It was composed between 1500-900 B.C, making it widely regarded as one of the oldest music systems in the world. Traditionally, it has been enjoyed as not just a means for aesthetic pleasure, but a way of realizing inner happiness and self-release. There is also a strong sense of spirituality associated with Hindustani Music, which is essential for its study and practice. The most striking feature of Hindustani Music is its imaginative and improvised nature, which implies that there are no written script even while performing. There are no fixed compositions that the artist has to adhere to. In effect, the entire performance is an extempore, and the artist is playing the role of the singer, composer and the conductor all at the same time. The artist adheres to a concept called as the Raga. The Raga is the central melodic concept in Indian music. According to Rao et al., it is neither a tune, nor is it a modal scale, but rather a continuum with scale and tune as its extremes. Broadly speaking, it can be termed as a melodic mode or tonal matrix possessing a rigid and specific individual identity, yet bearing immense potential for infinite improvisatory possibilities. The raga serves as a basic grammar for composition and improvisation in Indian music.&lt;/p&gt;

&lt;p&gt;The use of statistical and probabilistic tools in Musicology is not new. Temperley and Beran have very systematically laid down the probabilistic and statistical techniques used for music analyses respectively. The well-defined structure of a Raga makes the possibility of the usage of probabilistic and stochastic modeling techniques extremely favourable. Although the notes and intonations in an artist’s rendition are inherently unpredictable, there are some properties of the raga, e.g. the most dominant note (vadi), the second most dominant note (samvadi) and the identifying tonic pattern(pakad), which are more-or-less kept constant. This has led to the development of several approaches for automatic classification and clustering of ragas. The task of raga identification has been a subject of great curiosity among researchers. Given the fact that music is an art, and the plethora of improvisation possibilities that the artist can employ, even seasoned human listeners sometimes find it difficult to identify ragas. Indeed, some ragas have very minute differences, some have the same scale and notes, however the pattern of their usage and the corresponding emotions induced can be extremely different. One of the most notable examples is Raga Bhupali and Raga Deshkar. Some sophisticated automatic techniques have, however been fairly successful as they are able to infer a whole body of information about the raga using techniques such as Pitch Distribution Methods, Transposition Invariance Uniform Time Scaling and Vector Space Modeling. My research and experiments over the course of this seminar will attempt to inquire into the different approaches used for feature extraction and statistical analysis of ragas, and how these are further employed for Tonic Similarity Calculation, Raga Identification, Mood Detection, Detection and Classification of Melodic Motifs and Automatic Music Composition.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>On Responsible and Ethical Robotics</title>
   <link href="http://localhost:4000/2017/04/30/responsible-robotics/"/>
   <updated>2017-04-30T00:00:00+02:00</updated>
   <id>http://localhost:4000/2017/04/30/responsible-robotics</id>
   <content type="html">&lt;p&gt;Ever since the inception of Artificial Intelligence and Robotics as a discipline, the aim of researchers has been to make machines as intelligent as possible. In other words, to make machines function as if they had their own mind. Although this presents an exciting prospect for humanity, I believe that we would have to collectively shoulder the moral and ethical responsibilities associated with these efforts. In my opinion, creating machines with minds would be tantamount to giving birth to a whole new species, which we might or might not have full control over.&lt;/p&gt;

&lt;p&gt;This exciting (and sometimes haunting) prospect makes Robotics and AI much more than a standalone discipline. It requires a culmination of thoughts, concepts and processes from several other sciences and arts, such as Psychology, Anthropology, Ethics, Law, Production Engineering and several others. This means that future robotics doesn’t just have to ensure good design and high productivity, but it also needs to take into account all the other humane and ethical factors. Some intriguing questions that immediately come to mind are: Should Robots have rights? Should there be a maximum time limit for which they can be put to work? For a sustainable and harmonious future, we would need answers to such questions, and this would require knowledge about not just artificial intelligence, but how it intimately interacts with the other scientific fields mentioned above.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>About Jekyll</title>
   <link href="http://localhost:4000/2016/11/22/whats-jekyll/"/>
   <updated>2016-11-22T00:00:00+01:00</updated>
   <id>http://localhost:4000/2016/11/22/whats-jekyll</id>
   <content type="html">&lt;p&gt;This website is maintained using &lt;a href=&quot;http://jekyllrb.com&quot;&gt;Jekyll&lt;/a&gt;. Jekyll is a static site generator, an open-source tool for creating simple yet powerful websites of all shapes and sizes. From &lt;a href=&quot;https://github.com/mojombo/jekyll/blob/master/README.markdown&quot;&gt;the project’s readme&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jekyll is a simple, blog aware, static site generator. It takes a template directory and spits out a complete, static website suitable for serving with Apache or your favorite web server. This is also the engine behind GitHub Pages, which you can use to host your project’s page or blog right here from GitHub.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Find out more by &lt;a href=&quot;https://github.com/mojombo/jekyll&quot;&gt;visiting the project on GitHub&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>From the Old Archives - The Pursuit of Optimization</title>
   <link href="http://localhost:4000/2014/12/10/the-pursuit-of-optimization/"/>
   <updated>2014-12-10T00:00:00+01:00</updated>
   <id>http://localhost:4000/2014/12/10/the-pursuit-of-optimization</id>
   <content type="html">&lt;p&gt;Plain and simple, optimization is essentially the art, science and mathematics of choosing the best among a given set of finite or infinite alternatives. It gets as close to real life as it can. Optimization Problems are one of the most important as well as critical problems faced by man, given the basic principle of Economics that our wants are endless, and resources, finite. It’s an inter-disciplinary subject, cutting across Economics, Mathematics, Engineering and Natural Sciences.&lt;/p&gt;

&lt;p&gt;According to Roman Legend, the earliest possible mention of an optimization problem was in 500 BCE in the tale of Princess Dido. She was fleeing from the prosecution of her brother and a piece of land on the Mediterranean coast caught her fancy. She made a deal with the local leader. She requested him to cut a bull’s hide into thin strips and tie them up and enclose as much land as one can with it. In modern day language the problem is mathematically stated as follows - &lt;em&gt;Among all closed curves of a given length find the one that encloses maximum area&lt;/em&gt;. This is called the &lt;em&gt;Isoperimetric problem&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Great minds like Lagrange, Gauss, Newton, Bernoulli and Euler have all had significant contributions to the Optimization Theory, but a significant impetus was provided to it with the development of Linear Programming as an Optimization Technique. A linear programming problem consists of linear functions as objective and constraints. It became apparent that linear programming has tremendous applications in economics, military operations, business, engineering, etc. It was the development of the simplex method for solving linear programming problems that became the turning point of the subject.&lt;/p&gt;

&lt;p&gt;In the field of Computer Sciences, Algorithmics deals with the problems of optimization and how to devise the most optimal solution. There are several algorithms which have been developed over the years to tackle problems of the kind. Russian Novelist Ivan Turgenev said - &lt;em&gt;Whatever man prays for, he prays for a miracle. Every prayer reduces itself to this—Great God, grant that twice two be not four.&lt;/em&gt; This would make absolute sense to a computer scientist, who knows that if optimization problems are tried to be solved using the Brute-Force or Divide-and-Conquer mechanism, it would lead to exponential complexity, which is computationally the most tedious calculation possible. Even for an input size as small as 40, and with ample processing power, the solution may take several minutes, or probably hours to compute.
In the above situation, Richard Bellman came with an alternative in the 1950s, which we now know as &lt;em&gt;‘Dynamic Programming’&lt;/em&gt;. On analysis, it is not tough to show that Dynamic Programming yields the solution of several optimization problems in Polynomial Time, which is a massive leap from the exponential time complexity given by its Brute-Force counterpart.&lt;/p&gt;

&lt;p&gt;Dynamic Programming believes that optimal solutions to a problem incorporate optimal solutions to its related sub-problems, which may be solved independently. It works as follows: having observed that a naïve recursive solution is inefficient because it solves the same sub problems repeatedly, we arrange for each sub-problem to be solved only once, saving its solution. If we need to refer to this sub-problem’s solution again later, we can just look it up, rather than recompute it. Dynamic Programming thus uses additional memory to save computation time.
Because of its efficiency and ease of solving computationally demanding optimization problems, Dynamic Programming has retained itself as a Programmer’s Choice, and search engines like Google, social networks like Facebook and Twitter all have numerous usages of Dynamic Programming at each stage of their coding process.&lt;/p&gt;
</content>
 </entry>
 

</feed>
